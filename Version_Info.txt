   Key Legend:
                -- = current version
                -wor: = working on this ver
                 <-x_x-> = bug
                 |x_x| = bug fixed
                 <-o_o-> = design issue
                 |o_o| = design issue fixed


                     ~Updating to repo~
               | --------------------------- |
               | v# : Short Version Title    |
               | Description: v# description |
               | --------------------------- |

----------------------------    ----------------------------   ------------------------- ------------------------------
v0 Continuation: This is a continuation of respo Ai_Development_0, will be studying A.i a bit more in-depth
                        As of now just created the respo, with the necassary files to start the program. made a
                        version_info.txt, readme, and chap1. will be reading pythonmachinelearning -
                        The Python Machine Learning Ecosystem Chap1 at the moment.

v1 Respo Fixed: Fixed couple of issues with v0, now the README.md can be seen & Version_Info.txt on the 1st page
                once a user clicks on the respo. Also modified the venv/changed location of the files to second folder.
                Instead of have to click on 3 folders to see a program.

v2 PyCharm & Jupyter Notebook: Just got started on Jupyter for learning a bit more about pandas/aquiring data
                                from iris datasets, will be making a new folder to hold jupyter programs to seperate it
                                from pycharm files to help organize a bit. As of now I'm going deep in A.I/machine development
                                this is going to be a blast!

v3 DataFrame Pandas: testing some notes for using pandas and df for gathering data @ file dataset_for_jupyter.ipnb

v4 Jupyter Theme Changed & Notes added: Link to help with changing Jupyter theme to 'dark mode'
                                            link: https://www.youtube.com/watch?v=gjxrDf6Pp6M

                                            github link for shortcut for adding new line on jupyter:
                                            https://github.com/jupyter/notebook/issues/3918

                                            df.iloc[:3,:2]
                                            .iloc notation and the Python list slicing syntax,
                                             we were able to select a slice of this DataFrame.

                                             Added a new file called Demo of Jupyter, just a mini file testing Jupyter
                                             Shift-Enter to auto start the program,
                                             esc-b to make a new line

v5 Testing .iloc & loc iterators: -using list iterator to select just the width feature columns:
                                           df.loc[:3, [x for x in df.columns if 'width' in x]]
                                           'reate a list that is a subset of all columns. df.columns returns a list
                                           of all columns, and our iteration uses a conditional statement to
                                           select only those with width in the title'

                                           df.iloc[:4,:2] to select sepal length & sepal width

                                           df.iloc[:1,:5] selecting -> 	sepal length (cm)	sepal width (cm)
                                           petal length (cm)	petal width (cm) & 	species

                                           file changes are @ dataset_for_jupyter.ipynb
----------------------------    ----------------------------   ------------------------- ------------------------------
v6 Selecting Specific Data From The Subset :  -> df['species'].unique() -> aquires the array and dtype which is int64

                                            -> df[df['species']==2] -> aquires the species sepal info and species #

                                           -> df[(df['species']==2)&(df['petal width (cm)']>2.2)] ->
                                            gets the species info that is greater than 2.2

                                            -> df.describe() just describes the information / give stats

                                            -> df.describe(percentiles=[.1,.2,.3,.4,.5,.6,.7,.8,.9])
                                                Gives the information that is more specific if the user wishes to get more
                                                precise measurments of the data on percentiles goes from 10% - 90% aka
                                                max

                                            -> df.corr() checks the correlation between the data


                                       v6.5 README.md Edit: Updated the README.md to include commas helps with the
                                                              flow statement of the sentence.


v7 Visualization of the Data: Made a new file called visualize.ipynb, updated py_chap1_source.py
                                  to accomadate the the info for graphing & made a new folder
                                  to hold the ipynb files called ipnb_files
                                  Installed matplotlib & jupyter onto pycharm as well.


v8 Graph Info:    For visualize.ipynb the following information is:
                - Graph info & explaination
                # creates the subplot -> 8inch width by 4inch height
                fig, ax = plt.subplots(figsize=(10,5))

                #this plots the histogram 4 petal width from iris df
                #by naming it .hist then pass the data, auto set the color to green
                ax.hist(df['petal width (cm)'], color='green');

                # set the y label position / font size
                ax.set_ylabel('Count', fontsize=14)

                # set the x label position / font size
                ax.set_xlabel('Width', fontsize=14)

                # set the graph title , y position & font size
                plt.title('Iris Petal Width', fontsize=14, y=1.01)


v9 Multi Graphs: on visualize.ipynb line [20] 4graphs are and shown to the user with the data for
                    Iris Petal Width , Iris Petal Length , Iris Sepal Width & Iris Sepal length. With
                    color codes for their graph color distinguishing from each other.
---------------------------    ----------------------------   ------------------------- ------------------------------
v10 ScatterPlot & Line Graph: 2 new graphs has been created 1 with Scatter Plot @ line [5] that puts the data on
                                a scatter format, while the line graph @ line [6] just displays the information as a
                                line for the petal information.

v11 Bar Graph : creation for Bar graph located @ line [7] for visualize.ipynb just a quick
                    example on creating this graph with comments explaining some of its
                    features ^_*

v12 Installed Seaborn: installed seaborn for more in-depthstatistical visualizations
               seaborn link/doc : http://seaborn.pydata.org/index.html
                @ line[17] basic intro to seaborn -> by importing it and showing the species information
                on multi graphs with either line, scatter graphs showing sepal & petal data.

                @ line [18] shows Violin Plots which are graph format that shows both sepal & petal information

v13 Map Function: just simple returns a map object of the information. in this case species
                    df['species'] = df['species'].map({0: 'SET', 1: 'VER', 2: 'VIR'})
                    'map function over each of the values of the existing species column. As each value was found in
                    the Python dictionary, it was added to the return series. We assigned this return series to the same
                    species name, so it replaced our original species column. Had we chosen a different name, say short code,
                    that column would have been appended to the DataFrame, and we would then have the original species column
                     plus the new short code column. '


v14 Apply Map,Groupby,Sklearn: perform a function across all data cells in your DataFrame.
                This is where applymap is the correct tool.

                more info for pandas/pydata docs : https://pandas.pydata.org/pandas-docs/stable/
                link for sklearn model: https://scikit-learn.org/stable/index.html
                stats model is mostly used for 'exploring data, estimating models, and running statistical tests'
                pip install sklearn onto pycharm venv @ aimech_venv


v15 Machine Find Apartments: new file created @ py_chap2 -> mach_find_apts.ipynb. For now the program gets http
                                from renthop from the chicago area for apts.
                                just for now prints content but at raw info.

---------------------------    ----------------------------   ------------------------- ------------------------------
v16 Installed Html5lib , bs4: Modified html5lib to html.parser after obtaing a tree error for the scan. The bug is fixedf
                                thanks @ stackoverflow link :
                                https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste

                                file renthop_scan.py & mach_find.apts.ipynb can now scan the site and order the info
                                to a more readab. format.

v17 Basic Mach Scan: basic scan of renthop for 1 apt for its url link, address, neighborhood, price range, bed # &
                            bathroom #


v18 25 Pages Scan: Aquired Jupyter NotebooK Command keys list :
                        http://maxmelnick.com/2016/04/19/python-beginner-tips-and-tricks.html

                        mach_find_apts.ipynb can now scan for apts within by scanning 4 25 pages for prices min
                        of 1.5k to 3.5k

v19 Jupyter DF Scan: @ mach_find_apts.ipynb scanned chicago apts in which aquired a more detailed results of the
                        apt's listings, address, url, bed,bathrooms, etc


v20 Neighborhood Info: Cleaning the info to get more precise data on the neighborhood / will improve on giving
                            user the choice on which neighborhood they are interested in renting out.


v21 Map Api Halt:   will find a new solution to aquire map api, google map api is not an option at this moment
                          / work on chp2 in the near future once I aquired an alternative map api

                          for the next version the program will be based on a msg/ flight fare that will send the user
                           airplane $ via text.

---------------------------    ----------------------------   ------------------------- ------------------------------
v22 Proj Start Mini App: mini app on helping the user find cheap airline tickets then sending a txt to the user once
                            the user accepted getting notifcations on updates regarding the airline that they want to
                            ride on.


v23 Main Focus: monitor the price of airline tickets that are the cheapest mostly looking for 'mistake fare'
                    Objectives to complete:
                    # aquire airplaine ticket
                    # web scrap the data
                    # send Txts to phone


v24 Pip install ChromeDriver & Selenium <-x_x->: installed ChromeDriver & Selenium, made a folder to hold ChromeDriver to
                                            activate the program airline_cheap_find.py

                                            On jupyter file -> find_airline_ticket_cheap.ipynb the module if having
                                            difficulity aquiring selenium will fix this issue shortly.


                                            v24.5 Deleted .Zip File: Deleted Zip File since most people will have
                                                                        different verisons of chrome driver
                                              link for Chrome Driver: https://chromedriver.chromium.org/


v25 Basic Image ScreenShot: file airline_cheap.find.py can now save the image screenshot when a user has opened
                                the airline line of their choosing. It will then name it incrementally 0 and up.


v26 Jupyter Fixing: will be finding a solution to the Jupyter issue/updating on a solution for version 24.
                        pip installed IPython

v27 Jupyter Fixed: Solution to selenium error can be found @ https://www.youtube.com/watch?v=FtVQ4Nui4l8
                        cmd -> pip install selenium -> python -> import selenium -> quit().

                        The file find_airline_ticket_cheap.ipynb can now process the file and save the img info onto
                        screenshot folder while printing out a success message.

---------------------------    ----------------------------   ------------------------- ------------------------------
v28 Google Api Required: Updated find_airline_ticket_cheap.ipynb with fixes.
                               ->  Google Api is required to continue this mini project of
                                    aquiring flight data, will work on this and chap2 in the near future
                                    pretty disappointed but Ill finish these 2 once I aquire more resources to get an
                                    api from google map's
                                    link for google map platform:
                                    https://developers.google.com/maps/documentation


v29 ChatBot Temp: Further learning about chatbots, will be using this knowledge to make a self learning a.i,
                    in remembrance of Tay. This is the first step of a long expedition to something much greater
                    the future holds many opportunities  ^_*


v30 ChatBot Med: bit indepth with this chat bot, granted its bit limited and it cant fully 'learn' just gets pre-defined
                    data that it can respond too, its basically clevorbot not fully self learning at this point, but im getting
                    their on future versions of chatbots. This respo @ chatbot will just be the basics of the basic
                    for chatbot info.

                    -pip install keras
                    -updated chatbot01.ipynb


v31 ChatBot Med Halt: couple of errors, will halt production and be starting to work on Data Analysis. then on Pytorch
                     which I'm highly excited to try out!!
 ---------------------------    ----------------------------   ------------------------- ------------------------------
v32 PyTorch Start: Pytorch / nueral networks & training -> made new folder called PyTorch, & pytorch_source to hold
                        the pysource
                        
 v33 Pytorch / tensorflow: https://pytorch.org/get-started/locally/
				made a regression_tensorflow folder will be further increasing skills in this section then will work on
					learning about Pytorch

v34 Image Reco: image detection in prog ^_^

v35 Info/Requirements Added: made a req.txt file using pip freeze >  requirements.txt , good training on making req.txt
                                files in the future as well, as organizing what the program has at the moment.

                                Installed tensorflow.
                                if your having diffic pip installing tensorflow check this stackflow link for the solution
                                https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip/55787868

--v36 Update Version: deleted tensorflow info, due to file being too large to upload onto github, will be making a new project
                        and connect it to this one for image_recog


